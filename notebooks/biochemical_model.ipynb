{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual Modeling with a Biochemical Network\n",
    "\n",
    "This workflow demonstrates counterfactual modeling using a [dynamic model of biochemical signaling in lung cancer](https://wwwdev.ebi.ac.uk/biomodels/BIOMD0000000427).\n",
    "\n",
    "## Model background\n",
    "\n",
    "### What is this?\n",
    "\n",
    "\n",
    "This is a dynamic model of cell signaling in lung cancer by [Bianconi et al 2012](https://wwwdev.ebi.ac.uk/biomodels/BIOMD0000000427). Visualization of the model: ![bianconi_viz](https://i.imgur.com/6KUXKsy.png)\n",
    "\n",
    "The nodes 'sos', 'ras', 'pi3k', 'akt', 'raf', 'mek', 'erk', and 'p90' represent concentrations of enzymatically active proteins at steady state.  This dynamic model is specified as a set of species and reactions between species using Michaelis-Menton kinetics.  The model can be downloaded from [biomodels.org](https://wwwdev.ebi.ac.uk/biomodels/BIOMD0000000427) as a file written in a markup language called SBML, which can be compiled with various software tools.\n",
    "\n",
    "A module in this repository called `cancer_signaling` uses structural causal modeling to represent the system at *steady state*.  This approach assumes the system is stochastic, and models the probability distribution of the concentrations of the proteins.  The derivations underlying the model can be found in the *bianconi_math* document.\n",
    "\n",
    "### Counterfactual reasoning on a biochemical model can inform experimental design.\n",
    "\n",
    "Suppose an experimentalist wanted to do an experiment on the system (eg. forcing a variable's value to increase or knocking it out).  Furthermore, suppose she already has data collected under entirely different conditions than in the proposed experiment.\n",
    "\n",
    "Counterfactual reasoning could simulate from a probability distribution representing the outcome of the experiment prior to spending the resources on the experiment.  This could save resources by, for example, prioritizing experiments more likely to produce interesting discoveries.\n",
    "\n",
    "### Who would use this?\n",
    "\n",
    "This type of dynamic model simulates biochemical reactions in cells. They are used in fields such as drug discovery and synthetic biology to model the effects of an intervention in the cellular system (such as a candidate compound or manipulation of the genetic machinery)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "from pprint import pprint\n",
    "import pyro\n",
    "from pyro.distributions import LogNormal\n",
    "from pyro import condition, do, infer, sample\n",
    "from pyro.infer import EmpiricalMarginal\n",
    "from pyro.infer.mcmc import MCMC\n",
    "from pyro.infer.mcmc.nuts import NUTS\n",
    "import torch\n",
    "\n",
    "from causal_demon.transmitters import cancer_signaling\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for inference\n",
    "\n",
    "Since the inference algorithm is not the focus of this tutorial, I hide the choice of algorithm in an abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_noise(model):\n",
    "    nuts_kernel = NUTS(model, adapt_step_size=True)\n",
    "    return MCMC(nuts_kernel, num_samples=500, warmup_steps=300)\n",
    "\n",
    "def infer_noise2(model):\n",
    "    return pyro.infer.Importance(model, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(marginal, name):\n",
    "    plt.hist([marginal() for _ in range(5000)])\n",
    "    plt.title(\"Marginal Histogram of {}\".format(name))\n",
    "    plt.xlabel(\"concentration\")\n",
    "    plt.ylabel(\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating \"wild type\" data from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Wild type\" refers to data forward-generated from the model. \n",
    "\n",
    "Pass in noise variables that capture the variation in the model.  Each noise term is modeled with a weakly informed prior. The `independent` method reshapes the distribution such that data replicates will be independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_vars = ['N_egf', 'N_igf', 'N_sos', 'N_ras', 'N_pi3k', 'N_akt', 'N_raf', 'N_mek', 'N_erk']\n",
    "noise_priors = {N: LogNormal(0, 10).independent() for N in noise_vars}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_shape` captures the dimensions of the data. Here we simulate 4 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'egf': tensor([ 1.3451e-04,  8.5265e-01, -5.9698e-07,  1.2893e+05]),\n",
       " 'igf': tensor([1.1811e+09, 8.2959e-05, 2.6991e-05, 4.0145e+07]),\n",
       " 'sos': tensor([1.1957e+05, 2.6486e-01, 3.8057e-03, 1.1350e+05]),\n",
       " 'ras': tensor([55184.7930,     1.4579, 77630.7500, 53698.1367]),\n",
       " 'pi3k': tensor([ 120010.9844,    1179.5409, 4540044.5000,  119999.7891]),\n",
       " 'akt': tensor([405095.7500,  29134.3945, 598950.0625, 437960.0312]),\n",
       " 'raf': tensor([2171.0269,    0.1378, 1444.7947, 1316.2133]),\n",
       " 'mek': tensor([77864.0000,     4.9157, 47464.5547, 43546.7773]),\n",
       " 'erk': tensor([428376.6875,     94.5480, 362289.4375, 349577.0000])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_signaling(noise_priors, sample_shape=torch.Size([4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating an intervention experiment with the do-operator\n",
    "\n",
    "Suppose we have an *intervention query*:\n",
    "\n",
    "### Intervention Query: *What would happen if we blocked IGF and varied the amount of EGF?*\n",
    "\n",
    "We could answer this query with an experiment:\n",
    "* 3 conditions: EGF is varied from low (set to 800), medium (8000), to high (80000) concentrations\n",
    "* 2 replicates of each condition.\n",
    "* IGF is blocked (set to 0).\n",
    "\n",
    "Prior to running the experiment, we can simulate the experiment using this model.  \n",
    "\n",
    "**Why simulate experiments?**  Interventions with the `do` operator allow you to simulate the results of an experiment prior to spending the resources to conduct the experiment.\n",
    "\n",
    "The interventions on IFG and EGF in this example are one set from a very large set of possible interventions.  Which sent of interventions is the best?  You can answer this by defining a cost function on the experimental results, applying that function to simulated data, and iteratively searching for a set of interventions that optimizes that cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'akt': tensor([[391338.7188, 404718.7812, 407006.2500],\n",
      "        [392281.4375, 403664.8438, 573941.7500]]),\n",
      " 'egf': tensor([[  800.,  8000., 80000.],\n",
      "        [  800.,  8000., 80000.]]),\n",
      " 'erk': tensor([[5.5875e+03, 5.6264e+05, 2.0091e+04],\n",
      "        [9.7106e+05, 9.5360e+08, 5.2224e+05]]),\n",
      " 'igf': tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]),\n",
      " 'mek': tensor([[   293.2357, 469678.3750,    956.1735],\n",
      "        [    52.5269,   1588.2506, 209497.5625]]),\n",
      " 'pi3k': tensor([[ 108291.1875,  119667.8672,  119870.2812],\n",
      "        [ 109045.3203,  118715.5391, 1271766.0000]]),\n",
      " 'raf': tensor([[    8.2239, 60607.8164,    11.9922],\n",
      "        [    1.4725,    44.3995,  9023.0674]]),\n",
      " 'ras': tensor([[2.2908e+02, 4.7263e+06, 1.1677e+02],\n",
      "        [5.5069e+01, 1.1748e+03, 4.3400e+01]]),\n",
      " 'sos': tensor([[  0.5087,   5.0809, 136.9033],\n",
      "        [ 51.3112,   6.9473,  50.8112]])}\n"
     ]
    }
   ],
   "source": [
    "conditions = {\n",
    "    'egf': torch.tensor(\n",
    "        [\n",
    "            [800., 8000., 80000.],\n",
    "            [800., 8000., 80000.],\n",
    "        ]\n",
    "    ),\n",
    "    'igf': torch.zeros([2, 3])\n",
    "}\n",
    "initial_experiment = do(cancer_signaling, data=conditions)\n",
    "initial_results = initial_experiment(noise_priors, torch.Size([2, 3]))\n",
    "pprint(initial_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating a follow-up experiment using counterfactual inference\n",
    "\n",
    "Suppose that after that initial experiment, we want to try a new experiment under a different set of conditions.  We could repeat the simulation we just ran under the new conditions, but we can improve the quality of the simulation by using the old data.\n",
    "\n",
    "However, the old data was collected under different experimental conditions than in the proposed experiment.  This is addressed by posing a counterfactual query to the model:  \n",
    "\n",
    "### Counterfactual Query: *Given the observations of Erk after fixing IGF to 0, what would Erk have been if IGF were set to 8000?*\n",
    "\n",
    "The following illustrates how to use the counterfactual simulation algorithm to answer this query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditioning on previous observations\n",
    "\n",
    "Firstly, we pretend the simulated data from the previous section is real, and that we only collected data for Erk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erk_data = initial_results['erk']\n",
    "erk_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Condition the model of the initial experiment on the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.iarange(\"erk\", erk_data.shape[0]) as ind:\n",
    "    evidence = {'erk': initial_results['erk'][ind, :]}\n",
    "    initial_experiment_conditioned = condition(initial_experiment, data=evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Update the noise priors given the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log_prob() got an unexpected keyword argument 'sample_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/code/ppl_causal/venv/lib/python3.6/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mlog_prob_sum\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0msite_log_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_prob_sum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log_prob_sum'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e0317f25005c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_noise2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_experiment_conditioned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_priors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#noise_posteriors = {\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#    n: EmpiricalMarginal(model_posterior, sites=n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#    for n in noise_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/code/ppl_causal/venv/lib/python3.6/site-packages/pyro/infer/abstract_infer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_traces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/code/ppl_causal/venv/lib/python3.6/site-packages/pyro/infer/importance.py\u001b[0m in \u001b[0;36m_traces\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             model_trace = poutine.trace(\n\u001b[1;32m     44\u001b[0m                 poutine.replay(self.model, trace=guide_trace)).get_trace(*args, **kwargs)\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mlog_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/code/ppl_causal/venv/lib/python3.6/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mlog_prob_sum\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0msite_log_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                     \u001b[0msite_log_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite_log_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                     \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_prob_sum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite_log_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: log_prob() got an unexpected keyword argument 'sample_shape'"
     ]
    }
   ],
   "source": [
    "model_posterior = infer_noise2(initial_experiment_conditioned).run(noise_priors, sample_shape=torch.Size([2, 3]))\n",
    "#noise_posteriors = {\n",
    "#    n: EmpiricalMarginal(model_posterior, sites=n)\n",
    "#    for n in noise_vars\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Apply do-operator to original model to obtain a model of the new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = {\n",
    "    'egf': torch.tensor(\n",
    "        [\n",
    "            [800., 8000., 80000.],\n",
    "            [800., 8000., 80000.],\n",
    "        ]\n",
    "    ),\n",
    "    'igf': torch.tensor(\n",
    "        [\n",
    "            [8000., 8000., 8000.],\n",
    "            [8000., 8000., 8000.],\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "new_experiment = do(cancer_signaling, data=conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pass the updated noise marginals to the model of the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_marginals['N_egf'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_do_dist = infer_dist(cancer_do, noise_marginals)\n",
    "erk_cf_marginal = EmpiricalMarginal(cancer_do_dist, sites = 'erk')\n",
    "hist(erk_cf_marginal, 'Erk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extentions\n",
    "\n",
    "* Condition on IID data\n",
    "* Use SVI\n",
    "* Extend the model to accomadate uncertainty in parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
